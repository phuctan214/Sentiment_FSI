{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test_PhoBert.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Xhw6cKwV6YTh"},"source":["import os\n","import json\n","import gzip\n","import pandas as pd\n","from urllib.request import urlopen"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OwxiGCtE7n2f","executionInfo":{"status":"ok","timestamp":1605265358715,"user_tz":-420,"elapsed":28477,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"cc50dffe-ed53-40bd-936b-1ec0d1a71a0d","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive') "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X034_18V7jfP","executionInfo":{"status":"ok","timestamp":1605265382153,"user_tz":-420,"elapsed":883,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"6fa2b332-8abf-4943-d1b4-93425caa0660","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd '/content/drive/My Drive/FSI_Problem'\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/FSI_Problem\n"," Bert_Sentiment_AmazonDataset.ipynb\t   PhoBert_Sentiment.ipynb\n"," check_text.csv\t\t\t\t   svc_rbf.pkl\n"," Clone_Foody.ipynb\t\t\t   test.crash\n"," Concat_Data.ipynb\t\t\t   Test_ML.ipynb\n","'Copy of Test_Foody.ipynb'\t\t  'Test_ML with Tokenize.ipynb'\n","'Copy of Viblo_Sentiment.ipynb'\t\t   Test_PhoBert.ipynb\n"," Data\t\t\t\t\t   tfidf.pkl\n"," LR_Model.pkl\t\t\t\t   tfidf_rbf.pkl\n"," MultiBert_Sentiment_AmazonDataset.ipynb   train.crash\n"," PhoBERT_base_fairseq\t\t\t   train_dataloader.pkl\n"," PhoBERT_base_fairseq.tar.gz\t\t   val_dataloader.pkl\n"," PhoBERT_base_transformers\t\t   vncorenlp\n"," PhoBERT_base_transformers.tar.gz\t   X1.pkl\n"," PhoBert_Sentiment_Foody.ipynb\t\t   y1.pkl\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nABZCLt7LFdJ","executionInfo":{"status":"ok","timestamp":1605265436864,"user_tz":-420,"elapsed":938,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"6d23d2a7-7f54-4de4-d160-38739a5fd022","colab":{"base_uri":"https://localhost:8080/"}},"source":["data = pd.read_csv('Data/datadepvail.csv') \n","data = data.drop(['Unnamed: 0'],axis=1)\n","data.info() "],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 9136 entries, 0 to 9135\n","Data columns (total 2 columns):\n"," #   Column   Non-Null Count  Dtype  \n","---  ------   --------------  -----  \n"," 0   comment  9132 non-null   object \n"," 1   labels   9128 non-null   float64\n","dtypes: float64(1), object(1)\n","memory usage: 142.9+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l-pGEVBxLI_X","executionInfo":{"status":"ok","timestamp":1605265451807,"user_tz":-420,"elapsed":1099,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"fef75b55-e507-472c-88ae-ca2aab2ee29a","colab":{"base_uri":"https://localhost:8080/"}},"source":["data = data.dropna()  \n","data['labels'].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0    3925\n","2.0    3125\n","1.0    2074\n","Name: labels, dtype: int64"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"mUYxLVJ4Ryex","executionInfo":{"status":"ok","timestamp":1605265472838,"user_tz":-420,"elapsed":863,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"2b8645d8-95ed-4e96-95a7-e1005b68bb1d","colab":{"base_uri":"https://localhost:8080/"}},"source":["data.info()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 9124 entries, 0 to 9135\n","Data columns (total 2 columns):\n"," #   Column   Non-Null Count  Dtype  \n","---  ------   --------------  -----  \n"," 0   comment  9124 non-null   object \n"," 1   labels   9124 non-null   float64\n","dtypes: float64(1), object(1)\n","memory usage: 213.8+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bzMSIT9yLNBF"},"source":["a =list(data[data['label'] ==0].index)\n","b = []\n","for i in range(0,800):\n","  b.append(a[i]) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x3p_wogsLN8b","executionInfo":{"status":"ok","timestamp":1604043213859,"user_tz":-420,"elapsed":948,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"44ab7321-48e8-4902-8a72-0f886ee404a6","colab":{"base_uri":"https://localhost:8080/"}},"source":["data= data.drop(b)\n","data['label'].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0    743\n","0.0    716\n","2.0    681\n","Name: label, dtype: int64"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"K1q9QQ_ybRCH"},"source":["data.to_csv('Data/data_check.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AnZ7d8tBLQH5"},"source":["X = data.comment.values\n","y = data.labels.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xOP4bKpqxn64"},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15,random_state = 7)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HQ2mE6YpiAUv","executionInfo":{"status":"ok","timestamp":1605265496233,"user_tz":-420,"elapsed":794,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"50131e98-9ff2-4cf9-a23d-a2e236c55e6e","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(sum(y_train==0))\n","print(sum(y_train==1))\n","print(sum(y_train==2))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3366\n","1735\n","2654\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sg7TR1ZK8HeG","executionInfo":{"status":"ok","timestamp":1605265502946,"user_tz":-420,"elapsed":4162,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"5d49d38b-bd4d-4afb-d88d-2ae50b393278","colab":{"base_uri":"https://localhost:8080/"}},"source":["import torch\n","\n","if torch.cuda.is_available():       \n","    device = torch.device(\"cuda\")\n","    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n","    print('Device name:', torch.cuda.get_device_name(0))\n","\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","Device name: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pZpIB2FR8qs7","executionInfo":{"status":"ok","timestamp":1605265574740,"user_tz":-420,"elapsed":63876,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"e330f183-0275-4c3b-9d54-907b2e37cb6a","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip3 install fairseq\n","!pip3 install fastbpe\n","!pip3 install vncorenlp\n","!pip3 install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting fairseq\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/5f/fddba88a1478e6223241065f779e3eb547e0a4db0a16ae46a2cf92a257b9/fairseq-0.10.0.tar.gz (677kB)\n","\r\u001b[K     |▌                               | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 29.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 21.1MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 24.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 23.3MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 17.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 18.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 16.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 389kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 419kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 450kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 471kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 481kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 501kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 512kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 532kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 542kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 563kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 583kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 604kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 624kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 645kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 665kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 686kB 17.6MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.3)\n","Collecting sacrebleu>=1.4.12\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.6MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.7)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.7.0+cu101)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.21)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n","Collecting hydra-core\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/03/fee705ef16675a103d8e929255f5fa0ee79432ac38bafad6935d6ad170f9/hydra_core-1.0.3-py3-none-any.whl (122kB)\n","\u001b[K     |████████████████████████████████| 122kB 58.5MB/s \n","\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.5.3)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (3.7.4.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n","Collecting omegaconf>=2.0.2\n","  Downloading https://files.pythonhosted.org/packages/e5/f6/043b6d255dd6fbf2025110cea35b87f4c5100a181681d8eab496269f0d5b/omegaconf-2.0.5-py3-none-any.whl\n","Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from hydra-core->fairseq) (3.3.0)\n","Collecting antlr4-python3-runtime==4.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n","\u001b[K     |████████████████████████████████| 112kB 57.7MB/s \n","\u001b[?25hCollecting PyYAML>=5.1.*\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n","\u001b[K     |████████████████████████████████| 276kB 50.9MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core->fairseq) (3.4.0)\n","Building wheels for collected packages: fairseq\n","  Building wheel for fairseq (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairseq: filename=fairseq-0.10.0-cp36-cp36m-linux_x86_64.whl size=2632011 sha256=0ebd964f5abea7f43cc1a9fb0e73cdd7483c2f0e9ade619cbd7d1bd2c8e1d34a\n","  Stored in directory: /root/.cache/pip/wheels/cc/23/f1/b5dba0d2da81577b3c426ef983e4bc021e5f751f35c5ba94a2\n","Successfully built fairseq\n","Building wheels for collected packages: antlr4-python3-runtime, PyYAML\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp36-none-any.whl size=141230 sha256=3ca1d397e7cfcb10e0e45f5e446a2832a295929c253b49ce5aaf680fb1230966\n","  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44619 sha256=783b8a676d8392a6b41f074f554e66fce4a708764e6244dd42c85e3965f6228b\n","  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n","Successfully built antlr4-python3-runtime PyYAML\n","Installing collected packages: portalocker, sacrebleu, PyYAML, omegaconf, antlr4-python3-runtime, hydra-core, fairseq\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-5.3.1 antlr4-python3-runtime-4.8 fairseq-0.10.0 hydra-core-1.0.3 omegaconf-2.0.5 portalocker-2.0.0 sacrebleu-1.4.14\n","Collecting fastbpe\n","  Downloading https://files.pythonhosted.org/packages/e1/37/f97181428a5d151501b90b2cebedf97c81b034ace753606a3cda5ad4e6e2/fastBPE-0.1.0.tar.gz\n","Building wheels for collected packages: fastbpe\n","  Building wheel for fastbpe (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastbpe: filename=fastBPE-0.1.0-cp36-cp36m-linux_x86_64.whl size=481475 sha256=604c40943240a35c42a710e560b885d34c18cdd72566a1b04a3e6147592dd528\n","  Stored in directory: /root/.cache/pip/wheels/f3/0c/9c/fc62058b4d473a5602bcd3d3edfece796f123875379ea82d79\n","Successfully built fastbpe\n","Installing collected packages: fastbpe\n","Successfully installed fastbpe-0.1.0\n","Collecting vncorenlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/c2/96a60cf75421ecc740829fa920c617b3dd7fa6791e17554e7c6f3e7d7fca/vncorenlp-1.0.3.tar.gz (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.7MB 11.2MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vncorenlp) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2020.6.20)\n","Building wheels for collected packages: vncorenlp\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-cp36-none-any.whl size=2645934 sha256=909211f0b6d8678da800289df53250d19d21e38a83004b322c77501e08faddbb\n","  Stored in directory: /root/.cache/pip/wheels/09/54/8b/043667de6091d06a381d7745f44174504a9a4a56ecc9380c54\n","Successfully built vncorenlp\n","Installing collected packages: vncorenlp\n","Successfully installed vncorenlp-1.0.3\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/34/fb092588df61bf33f113ade030d1cbe74fb73a0353648f8dd938a223dce7/transformers-3.5.0-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 12.6MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 42.8MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting sentencepiece==0.1.91\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 48.1MB/s \n","\u001b[?25hCollecting tokenizers==0.9.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 49.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=fee338358f472b6e3d632d55000813fd8175c9c51722e9bcb07a647f6df3fdc1\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qXFEwblFPA6d","executionInfo":{"status":"ok","timestamp":1605265613914,"user_tz":-420,"elapsed":7010,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"8868f118-c6b0-4477-e75c-63f19b6426f7","colab":{"base_uri":"https://localhost:8080/"}},"source":["from vncorenlp import VnCoreNLP\n","rdrsegmenter = VnCoreNLP(\"/content/drive/My Drive/FSI_Problem/vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m') \n","\n","text = \"Đại học Bách Khoa Hà Nội.\"\n","\n","word_segmented_text = rdrsegmenter.tokenize(text) \n","print(word_segmented_text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[['Đại_học', 'Bách_Khoa', 'Hà_Nội', '.']]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WhvROI1u9AdX"},"source":["from fairseq.data.encoders.fastbpe import fastBPE\n","from fairseq.data import Dictionary\n","import argparse\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--bpe-codes', \n","    default=\"/content/drive/My Drive/FSI_Problem/PhoBERT_base_transformers/bpe.codes\",\n","    required=False,\n","    type=str,\n","    help='path to fastBPE BPE'\n",")\n","args, unknown = parser.parse_known_args()\n","bpe = fastBPE(args)\n","\n","# Load the dictionary\n","vocab = Dictionary()\n","vocab.add_from_file(\"/content/drive/My Drive/FSI_Problem/PhoBERT_base_transformers/dict.txt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3wCZR5GREBpA","executionInfo":{"status":"ok","timestamp":1605265629591,"user_tz":-420,"elapsed":787,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"7e8d1f52-bca5-407e-f7b7-e2ca6f16a007","colab":{"base_uri":"https://localhost:8080/"}},"source":["vocab.encode_line('<s> ' + 'Hôm_nay trời nóng quá nên tôi ở nhà viết Vi@@ blo@@ !' )"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([    0,  3791,  1027,   898,   204,    77,    70,    25,    69,   467,\n","         3696, 16856,   381,     2], dtype=torch.int32)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"UFFszZR8EnYZ"},"source":["import re\n","def text_preprocessing(text):\n","\n","    text = re.sub('[^a-zA-ZÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚÝàáâãèéêìíòóôõùúýĂăĐđĨĩŨũƠơƯưẠạẢảẤấẦầẨẩẪẫẬậẮắẰằẲẳẴẵẶặẸẹẺẻẼẽẾếỀềỂểỄễỆệỈỉỊịỌọỎỏỐốỒồỔổỖỗỘộỚớỜờỞởỠỡỢợỤụỦủỨứỪừỬửỮữỰựỲỳỴỵỶỷỸỹ0-9.,\"-]', ' ' ,text)\n","\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ZTIRA5WW3Sk","executionInfo":{"status":"ok","timestamp":1605265633931,"user_tz":-420,"elapsed":795,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"f55f3a7e-e356-4e98-a583-8ef6b7dd932c","colab":{"base_uri":"https://localhost:8080/"}},"source":["sample = X[20]\n","sample = text_preprocessing(sample)\n","splits = sample.strip().split(' ')\n","text = ' '.join(splits)\n","text = rdrsegmenter.tokenize(text)\n","text = ' '.join([' '.join(x) for x in text])\n","print(text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["rất là đẹp\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"njVSGBi0jL0v","executionInfo":{"status":"ok","timestamp":1605265636897,"user_tz":-420,"elapsed":774,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"61c62ab8-a602-4395-b9dc-e8388d552781","colab":{"base_uri":"https://localhost:8080/"}},"source":["y[20]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.0"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"obMikhehEsem"},"source":["import re\n","train_id, train_text, train_labels = [], [], []\n","val_id, val_text, val_labels = [], [], []\n","\n","for sample in X_train:\n","  sample = text_preprocessing(sample)\n","  \n","  splits = sample.strip().split(' ')\n","  text = ' '.join(splits)\n","  text = rdrsegmenter.tokenize(text)\n","  text = ' '.join([' '.join(x) for x in text])\n","\n","  train_text.append(text) \n","\n","for sample in X_val:\n","  sample = text_preprocessing(sample)\n","  \n","  splits = sample.strip().split(' ')\n","  text = ' '.join(splits)\n","  text = rdrsegmenter.tokenize(text)\n","  text = ' '.join([' '.join(x) for x in text])\n","\n","  val_text.append(text) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UIaBbhQ3GN03"},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","MAX_LEN = 250\n","\n","train_ids = []\n","for sent in train_text:\n","    subwords = '<s> ' + bpe.encode(sent)\n","    encoded_sent = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n","    train_ids.append(encoded_sent)\n","\n","val_ids = []\n","for sent in val_text:\n","    subwords = '<s> ' + bpe.encode(sent)\n","    encoded_sent = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n","    val_ids.append(encoded_sent)\n","    \n","train_ids = pad_sequences(train_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n","val_ids = pad_sequences(val_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ml7nLnYrGZAD"},"source":["train_masks = []\n","for sent in train_ids:\n","    mask = [int(token_id > 0) for token_id in sent]\n","    train_masks.append(mask)\n","\n","val_masks = []\n","for sent in val_ids:\n","    mask = [int(token_id > 0) for token_id in sent]\n","    val_masks.append(mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UuUjcbb7GfTv","executionInfo":{"status":"ok","timestamp":1605265693611,"user_tz":-420,"elapsed":808,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"f38107d8-89b0-478f-b90e-b6c3e788f241","colab":{"base_uri":"https://localhost:8080/","height":399}},"source":["print(train_ids[2])\n","train_text[2]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[    0    74    10    36   192 13304    51   265  2529   741     2     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'vẫn có nhiều điểm bất_tiện nhưng sản_phẩm đa chức_năng'"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"9y-8wjaFxNs1","executionInfo":{"status":"ok","timestamp":1605265714990,"user_tz":-420,"elapsed":18779,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"d9c30d43-e477-40d3-9d1c-0b0d5423efc1","colab":{"base_uri":"https://localhost:8080/"}},"source":["from transformers import BertModel, RobertaConfig, AdamW\n","\n","config = RobertaConfig.from_pretrained(\n","    \"/content/drive/My Drive/FSI_Problem/PhoBERT_base_transformers/config.json\", from_tf=False, num_labels = 2, output_hidden_states=False,\n",")\n","BERT_SA = BertModel.from_pretrained(\n","    \"/content/drive/My Drive/FSI_Problem/PhoBERT_base_transformers/model.bin\",\n","    config=config\n",") "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at /content/drive/My Drive/FSI_Problem/PhoBERT_base_transformers/model.bin were not used when initializing BertModel: ['roberta.embeddings.word_embeddings.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertModel were not initialized from the model checkpoint at /content/drive/My Drive/FSI_Problem/PhoBERT_base_transformers/model.bin and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"q2ovK6vtGvo-"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import torch\n","train_inputs = torch.LongTensor(train_ids)\n","val_inputs = torch.LongTensor(val_ids)\n","y_train = torch.tensor(y_train)\n","y_train = y_train.type(torch.LongTensor)\n","y_val = torch.tensor(y_val)\n","y_val = y_val.type(torch.LongTensor)\n","train_masks = torch.LongTensor(train_masks)\n","val_masks = torch.LongTensor(val_masks)\n","\n","train_data = TensorDataset(train_inputs, train_masks, y_train)\n","train_sampler = SequentialSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)\n","\n","val_data = TensorDataset(val_inputs, val_masks, y_val)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aYoIOzKFG0my","executionInfo":{"status":"ok","timestamp":1605265720757,"user_tz":-420,"elapsed":854,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"3fa3ae1d-1b04-4a4d-d86f-b5e4bb3f837d","colab":{"base_uri":"https://localhost:8080/"}},"source":["%%time\n","import torch\n","import torch.nn as nn\n","from transformers import BertModel\n","\n","# Create the BertClassfier class\n","class BertClassifier(nn.Module):\n","    \"\"\"Bert Model for Classification Tasks.\n","    \"\"\"\n","    def __init__(self, freeze_bert=False):\n","        \"\"\"\n","        @param    bert: a BertModel object\n","        @param    classifier: a torch.nn.Module classifier\n","        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n","        \"\"\"\n","        super(BertClassifier, self).__init__()\n","        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n","        D_in, H, D_out = 768, 50, 3\n","\n","        # Instantiate BERT model\n","        self.bert = BERT_SA\n","\n","        # Instantiate an one-layer feed-forward classifier\n","        self.classifier = nn.Sequential(\n","            nn.Linear(D_in, H),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(H, D_out)\n","        )\n","\n","        # Freeze the BERT model\n","        if freeze_bert:\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","        \n","    def forward(self, input_ids, attention_mask):\n","        \"\"\"\n","        Feed input to BERT and the classifier to compute logits.\n","        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n","                      max_length)\n","        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n","                      information with shape (batch_size, max_length)\n","        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n","                      num_labels)\n","        \"\"\"\n","        # Feed input to BERT\n","        outputs = self.bert(input_ids=input_ids,\n","                            attention_mask=attention_mask)\n","        \n","        # Extract the last hidden state of the token `[CLS]` for classification task\n","        last_hidden_state_cls = outputs[0][:, 0, :]\n","\n","        # Feed input to classifier to compute logits\n","        logits = self.classifier(last_hidden_state_cls)\n","        \n","        return logits"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 44 µs, sys: 0 ns, total: 44 µs\n","Wall time: 46.3 µs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WHzI9g0vHJzX"},"source":["from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","def initialize_model(epochs=4):\n","    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n","    \"\"\"\n","    # Instantiate Bert Classifier\n","    bert_classifier = BertClassifier(freeze_bert=False)\n","\n","    bert_classifier.to(device)\n","    \n","    optimizer = AdamW(bert_classifier.parameters(),\n","                      lr=5e-5,    # Default learning rate\n","                      eps=1e-8    # Default epsilon value\n","                      )\n","\n","    # Total number of training steps\n","    total_steps = len(train_dataloader) * epochs\n","\n","    # Set up the learning rate scheduler\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0, # Default value\n","                                                num_training_steps=total_steps)\n","    return bert_classifier, optimizer, scheduler\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bZ7cb80-IaDY"},"source":["import numpy as np\n","import random\n","def set_seed(seed_value=42):\n","    \"\"\"Set seed for reproducibility.\n","    \"\"\"\n","    random.seed(seed_value)\n","    np.random.seed(seed_value)\n","    torch.manual_seed(seed_value)\n","    torch.cuda.manual_seed_all(seed_value)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5WVJyQdYIa-u"},"source":["set_seed(42)    # Set seed for reproducibility\n","bert_classifier, optimizer, scheduler = initialize_model(epochs=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rk8X2DR8J2Yg","executionInfo":{"status":"ok","timestamp":1605265752695,"user_tz":-420,"elapsed":815,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"94622d4c-b713-429f-9fab-521594b55953","colab":{"base_uri":"https://localhost:8080/"}},"source":["for n,p in bert_classifier.named_parameters():\n","  print(p.device, ' ' , n)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda:0   bert.embeddings.word_embeddings.weight\n","cuda:0   bert.embeddings.position_embeddings.weight\n","cuda:0   bert.embeddings.token_type_embeddings.weight\n","cuda:0   bert.embeddings.LayerNorm.weight\n","cuda:0   bert.embeddings.LayerNorm.bias\n","cuda:0   bert.encoder.layer.0.attention.self.query.weight\n","cuda:0   bert.encoder.layer.0.attention.self.query.bias\n","cuda:0   bert.encoder.layer.0.attention.self.key.weight\n","cuda:0   bert.encoder.layer.0.attention.self.key.bias\n","cuda:0   bert.encoder.layer.0.attention.self.value.weight\n","cuda:0   bert.encoder.layer.0.attention.self.value.bias\n","cuda:0   bert.encoder.layer.0.attention.output.dense.weight\n","cuda:0   bert.encoder.layer.0.attention.output.dense.bias\n","cuda:0   bert.encoder.layer.0.attention.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.0.attention.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.0.intermediate.dense.weight\n","cuda:0   bert.encoder.layer.0.intermediate.dense.bias\n","cuda:0   bert.encoder.layer.0.output.dense.weight\n","cuda:0   bert.encoder.layer.0.output.dense.bias\n","cuda:0   bert.encoder.layer.0.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.0.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.1.attention.self.query.weight\n","cuda:0   bert.encoder.layer.1.attention.self.query.bias\n","cuda:0   bert.encoder.layer.1.attention.self.key.weight\n","cuda:0   bert.encoder.layer.1.attention.self.key.bias\n","cuda:0   bert.encoder.layer.1.attention.self.value.weight\n","cuda:0   bert.encoder.layer.1.attention.self.value.bias\n","cuda:0   bert.encoder.layer.1.attention.output.dense.weight\n","cuda:0   bert.encoder.layer.1.attention.output.dense.bias\n","cuda:0   bert.encoder.layer.1.attention.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.1.attention.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.1.intermediate.dense.weight\n","cuda:0   bert.encoder.layer.1.intermediate.dense.bias\n","cuda:0   bert.encoder.layer.1.output.dense.weight\n","cuda:0   bert.encoder.layer.1.output.dense.bias\n","cuda:0   bert.encoder.layer.1.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.1.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.2.attention.self.query.weight\n","cuda:0   bert.encoder.layer.2.attention.self.query.bias\n","cuda:0   bert.encoder.layer.2.attention.self.key.weight\n","cuda:0   bert.encoder.layer.2.attention.self.key.bias\n","cuda:0   bert.encoder.layer.2.attention.self.value.weight\n","cuda:0   bert.encoder.layer.2.attention.self.value.bias\n","cuda:0   bert.encoder.layer.2.attention.output.dense.weight\n","cuda:0   bert.encoder.layer.2.attention.output.dense.bias\n","cuda:0   bert.encoder.layer.2.attention.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.2.attention.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.2.intermediate.dense.weight\n","cuda:0   bert.encoder.layer.2.intermediate.dense.bias\n","cuda:0   bert.encoder.layer.2.output.dense.weight\n","cuda:0   bert.encoder.layer.2.output.dense.bias\n","cuda:0   bert.encoder.layer.2.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.2.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.3.attention.self.query.weight\n","cuda:0   bert.encoder.layer.3.attention.self.query.bias\n","cuda:0   bert.encoder.layer.3.attention.self.key.weight\n","cuda:0   bert.encoder.layer.3.attention.self.key.bias\n","cuda:0   bert.encoder.layer.3.attention.self.value.weight\n","cuda:0   bert.encoder.layer.3.attention.self.value.bias\n","cuda:0   bert.encoder.layer.3.attention.output.dense.weight\n","cuda:0   bert.encoder.layer.3.attention.output.dense.bias\n","cuda:0   bert.encoder.layer.3.attention.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.3.attention.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.3.intermediate.dense.weight\n","cuda:0   bert.encoder.layer.3.intermediate.dense.bias\n","cuda:0   bert.encoder.layer.3.output.dense.weight\n","cuda:0   bert.encoder.layer.3.output.dense.bias\n","cuda:0   bert.encoder.layer.3.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.3.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.4.attention.self.query.weight\n","cuda:0   bert.encoder.layer.4.attention.self.query.bias\n","cuda:0   bert.encoder.layer.4.attention.self.key.weight\n","cuda:0   bert.encoder.layer.4.attention.self.key.bias\n","cuda:0   bert.encoder.layer.4.attention.self.value.weight\n","cuda:0   bert.encoder.layer.4.attention.self.value.bias\n","cuda:0   bert.encoder.layer.4.attention.output.dense.weight\n","cuda:0   bert.encoder.layer.4.attention.output.dense.bias\n","cuda:0   bert.encoder.layer.4.attention.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.4.attention.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.4.intermediate.dense.weight\n","cuda:0   bert.encoder.layer.4.intermediate.dense.bias\n","cuda:0   bert.encoder.layer.4.output.dense.weight\n","cuda:0   bert.encoder.layer.4.output.dense.bias\n","cuda:0   bert.encoder.layer.4.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.4.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.5.attention.self.query.weight\n","cuda:0   bert.encoder.layer.5.attention.self.query.bias\n","cuda:0   bert.encoder.layer.5.attention.self.key.weight\n","cuda:0   bert.encoder.layer.5.attention.self.key.bias\n","cuda:0   bert.encoder.layer.5.attention.self.value.weight\n","cuda:0   bert.encoder.layer.5.attention.self.value.bias\n","cuda:0   bert.encoder.layer.5.attention.output.dense.weight\n","cuda:0   bert.encoder.layer.5.attention.output.dense.bias\n","cuda:0   bert.encoder.layer.5.attention.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.5.attention.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.5.intermediate.dense.weight\n","cuda:0   bert.encoder.layer.5.intermediate.dense.bias\n","cuda:0   bert.encoder.layer.5.output.dense.weight\n","cuda:0   bert.encoder.layer.5.output.dense.bias\n","cuda:0   bert.encoder.layer.5.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.5.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.6.attention.self.query.weight\n","cuda:0   bert.encoder.layer.6.attention.self.query.bias\n","cuda:0   bert.encoder.layer.6.attention.self.key.weight\n","cuda:0   bert.encoder.layer.6.attention.self.key.bias\n","cuda:0   bert.encoder.layer.6.attention.self.value.weight\n","cuda:0   bert.encoder.layer.6.attention.self.value.bias\n","cuda:0   bert.encoder.layer.6.attention.output.dense.weight\n","cuda:0   bert.encoder.layer.6.attention.output.dense.bias\n","cuda:0   bert.encoder.layer.6.attention.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.6.attention.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.6.intermediate.dense.weight\n","cuda:0   bert.encoder.layer.6.intermediate.dense.bias\n","cuda:0   bert.encoder.layer.6.output.dense.weight\n","cuda:0   bert.encoder.layer.6.output.dense.bias\n","cuda:0   bert.encoder.layer.6.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.6.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.7.attention.self.query.weight\n","cuda:0   bert.encoder.layer.7.attention.self.query.bias\n","cuda:0   bert.encoder.layer.7.attention.self.key.weight\n","cuda:0   bert.encoder.layer.7.attention.self.key.bias\n","cuda:0   bert.encoder.layer.7.attention.self.value.weight\n","cuda:0   bert.encoder.layer.7.attention.self.value.bias\n","cuda:0   bert.encoder.layer.7.attention.output.dense.weight\n","cuda:0   bert.encoder.layer.7.attention.output.dense.bias\n","cuda:0   bert.encoder.layer.7.attention.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.7.attention.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.7.intermediate.dense.weight\n","cuda:0   bert.encoder.layer.7.intermediate.dense.bias\n","cuda:0   bert.encoder.layer.7.output.dense.weight\n","cuda:0   bert.encoder.layer.7.output.dense.bias\n","cuda:0   bert.encoder.layer.7.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.7.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.8.attention.self.query.weight\n","cuda:0   bert.encoder.layer.8.attention.self.query.bias\n","cuda:0   bert.encoder.layer.8.attention.self.key.weight\n","cuda:0   bert.encoder.layer.8.attention.self.key.bias\n","cuda:0   bert.encoder.layer.8.attention.self.value.weight\n","cuda:0   bert.encoder.layer.8.attention.self.value.bias\n","cuda:0   bert.encoder.layer.8.attention.output.dense.weight\n","cuda:0   bert.encoder.layer.8.attention.output.dense.bias\n","cuda:0   bert.encoder.layer.8.attention.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.8.attention.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.8.intermediate.dense.weight\n","cuda:0   bert.encoder.layer.8.intermediate.dense.bias\n","cuda:0   bert.encoder.layer.8.output.dense.weight\n","cuda:0   bert.encoder.layer.8.output.dense.bias\n","cuda:0   bert.encoder.layer.8.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.8.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.9.attention.self.query.weight\n","cuda:0   bert.encoder.layer.9.attention.self.query.bias\n","cuda:0   bert.encoder.layer.9.attention.self.key.weight\n","cuda:0   bert.encoder.layer.9.attention.self.key.bias\n","cuda:0   bert.encoder.layer.9.attention.self.value.weight\n","cuda:0   bert.encoder.layer.9.attention.self.value.bias\n","cuda:0   bert.encoder.layer.9.attention.output.dense.weight\n","cuda:0   bert.encoder.layer.9.attention.output.dense.bias\n","cuda:0   bert.encoder.layer.9.attention.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.9.attention.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.9.intermediate.dense.weight\n","cuda:0   bert.encoder.layer.9.intermediate.dense.bias\n","cuda:0   bert.encoder.layer.9.output.dense.weight\n","cuda:0   bert.encoder.layer.9.output.dense.bias\n","cuda:0   bert.encoder.layer.9.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.9.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.10.attention.self.query.weight\n","cuda:0   bert.encoder.layer.10.attention.self.query.bias\n","cuda:0   bert.encoder.layer.10.attention.self.key.weight\n","cuda:0   bert.encoder.layer.10.attention.self.key.bias\n","cuda:0   bert.encoder.layer.10.attention.self.value.weight\n","cuda:0   bert.encoder.layer.10.attention.self.value.bias\n","cuda:0   bert.encoder.layer.10.attention.output.dense.weight\n","cuda:0   bert.encoder.layer.10.attention.output.dense.bias\n","cuda:0   bert.encoder.layer.10.attention.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.10.attention.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.10.intermediate.dense.weight\n","cuda:0   bert.encoder.layer.10.intermediate.dense.bias\n","cuda:0   bert.encoder.layer.10.output.dense.weight\n","cuda:0   bert.encoder.layer.10.output.dense.bias\n","cuda:0   bert.encoder.layer.10.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.10.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.11.attention.self.query.weight\n","cuda:0   bert.encoder.layer.11.attention.self.query.bias\n","cuda:0   bert.encoder.layer.11.attention.self.key.weight\n","cuda:0   bert.encoder.layer.11.attention.self.key.bias\n","cuda:0   bert.encoder.layer.11.attention.self.value.weight\n","cuda:0   bert.encoder.layer.11.attention.self.value.bias\n","cuda:0   bert.encoder.layer.11.attention.output.dense.weight\n","cuda:0   bert.encoder.layer.11.attention.output.dense.bias\n","cuda:0   bert.encoder.layer.11.attention.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.11.attention.output.LayerNorm.bias\n","cuda:0   bert.encoder.layer.11.intermediate.dense.weight\n","cuda:0   bert.encoder.layer.11.intermediate.dense.bias\n","cuda:0   bert.encoder.layer.11.output.dense.weight\n","cuda:0   bert.encoder.layer.11.output.dense.bias\n","cuda:0   bert.encoder.layer.11.output.LayerNorm.weight\n","cuda:0   bert.encoder.layer.11.output.LayerNorm.bias\n","cuda:0   bert.pooler.dense.weight\n","cuda:0   bert.pooler.dense.bias\n","cuda:0   classifier.0.weight\n","cuda:0   classifier.0.bias\n","cuda:0   classifier.3.weight\n","cuda:0   classifier.3.bias\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4B-QrsP1KFgB","executionInfo":{"status":"ok","timestamp":1602676745153,"user_tz":-420,"elapsed":1743,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"0ae013ae-1904-4ec2-d811-7de18631149c","colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["a = list(bert_classifier.named_parameters())\n","print(a[-4])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["('classifier.0.weight', Parameter containing:\n","tensor([[ 0.0276,  0.0300, -0.0085,  ...,  0.0203,  0.0096, -0.0338],\n","        [-0.0232,  0.0357,  0.0138,  ..., -0.0029, -0.0035, -0.0226],\n","        [ 0.0053, -0.0111, -0.0186,  ...,  0.0005, -0.0162, -0.0285],\n","        ...,\n","        [ 0.0269,  0.0332, -0.0217,  ...,  0.0001, -0.0270,  0.0292],\n","        [-0.0131, -0.0277,  0.0359,  ...,  0.0158,  0.0274, -0.0046],\n","        [-0.0348, -0.0182, -0.0180,  ..., -0.0194,  0.0054,  0.0325]],\n","       device='cuda:0', requires_grad=True))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l85qzIFGLmhs"},"source":["import random\n","import time\n","\n","# Specify loss function\n","loss_fn = nn.CrossEntropyLoss()\n","\n","def set_seed(seed_value=42):\n","    \"\"\"Set seed for reproducibility.\n","    \"\"\"\n","    random.seed(seed_value)\n","    np.random.seed(seed_value)\n","    torch.manual_seed(seed_value)\n","    torch.cuda.manual_seed_all(seed_value)\n","\n","def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n","    \"\"\"Train the BertClassifier model.\n","    \"\"\"\n","    # Start training loop\n","    print(\"Start training...\\n\")\n","    for epoch_i in range(epochs):\n","        # =======================================\n","        #               Training\n","        # =======================================\n","        # Print the header of the result table\n","        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n","        print(\"-\"*70)\n","\n","        # Measure the elapsed time of each epoch\n","        t0_epoch, t0_batch = time.time(), time.time()\n","\n","        # Reset tracking variables at the beginning of each epoch\n","        total_loss, batch_loss, batch_counts = 0, 0, 0\n","\n","        # Put the model into the training mode\n","        model.train()\n","\n","        # For each batch of training data...\n","        for step, batch in enumerate(train_dataloader):\n","            batch_counts +=1\n","            # Load batch to GPU\n","            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","\n","            # Zero out any previously calculated gradients\n","            model.zero_grad()\n","\n","            # Perform a forward pass. This will return logits.\n","            logits = model(b_input_ids, b_attn_mask)\n","\n","            # Compute loss and accumulate the loss values\n","            loss = loss_fn(logits, b_labels)\n","            batch_loss += loss.item()\n","            total_loss += loss.item()\n","\n","            # Perform a backward pass to calculate gradients\n","            loss.backward()\n","\n","            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            # Update parameters and the learning rate\n","            optimizer.step()\n","            scheduler.step()\n","\n","            # Print the loss values and time elapsed for every 20 batches\n","            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n","                # Calculate time elapsed for 20 batches\n","                time_elapsed = time.time() - t0_batch\n","\n","                # Print training results\n","                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n","\n","                # Reset batch tracking variables\n","                batch_loss, batch_counts = 0, 0\n","                t0_batch = time.time()\n","\n","        # Calculate the average loss over the entire training data\n","        avg_train_loss = total_loss / len(train_dataloader)\n","\n","        print(\"-\"*70)\n","        # =======================================\n","        #               Evaluation\n","        # =======================================\n","        if evaluation == True:\n","            # After the completion of each training epoch, measure the model's performance\n","            # on our validation set.\n","            val_loss, val_accuracy = evaluate(model, val_dataloader)\n","\n","            # Print performance over the entire training data\n","            time_elapsed = time.time() - t0_epoch\n","            \n","            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n","            print(\"-\"*70)\n","        print(\"\\n\")\n","    \n","    print(\"Training complete!\")\n","\n","\n","def evaluate(model, val_dataloader):\n","    \"\"\"After the completion of each training epoch, measure the model's performance\n","    on our validation set.\n","    \"\"\"\n","    # Put the model into the evaluation mode. The dropout layers are disabled during\n","    # the test time.\n","    model.eval()\n","\n","    # Tracking variables\n","    val_accuracy = []\n","    val_loss = []\n","\n","    # For each batch in our validation set...\n","    for batch in val_dataloader:\n","        # Load batch to GPU\n","        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","\n","        # Compute logits\n","        with torch.no_grad():\n","            logits = model(b_input_ids, b_attn_mask)\n","\n","        # Compute loss\n","        loss = loss_fn(logits, b_labels)\n","        val_loss.append(loss.item())\n","\n","        # Get the predictions\n","        preds = torch.argmax(logits, dim=1).flatten()\n","\n","        # Calculate the accuracy rate\n","        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n","        val_accuracy.append(accuracy)\n","\n","    # Compute the average accuracy and loss over the validation set.\n","    val_loss = np.mean(val_loss)\n","    val_accuracy = np.mean(val_accuracy)\n","\n","    return val_loss, val_accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KHNrlOmZL-4Y","executionInfo":{"status":"error","timestamp":1605266571709,"user_tz":-420,"elapsed":808485,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"bffbb4c9-4a2a-4f2c-ad98-ab3662e70e05","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train(bert_classifier, train_dataloader, val_dataloader, epochs=4, evaluation=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Start training...\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   1    |   20    |   1.129122   |     -      |     -     |   25.42  \n","   1    |   40    |   1.105973   |     -      |     -     |   24.53  \n","   1    |   60    |   1.076003   |     -      |     -     |   25.05  \n","   1    |   80    |   1.090855   |     -      |     -     |   25.38  \n","   1    |   100   |   1.084074   |     -      |     -     |   25.89  \n","   1    |   120   |   1.077338   |     -      |     -     |   26.16  \n","   1    |   140   |   1.081648   |     -      |     -     |   26.47  \n","   1    |   160   |   1.084343   |     -      |     -     |   26.59  \n","   1    |   180   |   1.071438   |     -      |     -     |   26.82  \n","   1    |   200   |   1.057792   |     -      |     -     |   27.09  \n","   1    |   220   |   1.070323   |     -      |     -     |   27.27  \n","   1    |   240   |   1.071327   |     -      |     -     |   27.27  \n","   1    |   242   |   1.129003   |     -      |     -     |   1.88   \n","----------------------------------------------------------------------\n","   1    |    -    |   1.083917   |  1.079517  |   40.91   |  336.91  \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   2    |   20    |   1.055857   |     -      |     -     |   28.57  \n","   2    |   40    |   1.086746   |     -      |     -     |   27.19  \n","   2    |   60    |   1.067651   |     -      |     -     |   27.26  \n","   2    |   80    |   1.072984   |     -      |     -     |   27.24  \n","   2    |   100   |   1.089339   |     -      |     -     |   27.19  \n","   2    |   120   |   1.083747   |     -      |     -     |   27.19  \n","   2    |   140   |   1.082829   |     -      |     -     |   27.24  \n","   2    |   160   |   1.076230   |     -      |     -     |   27.19  \n","   2    |   180   |   1.071189   |     -      |     -     |   27.23  \n","   2    |   200   |   1.066678   |     -      |     -     |   27.24  \n","   2    |   220   |   1.069111   |     -      |     -     |   27.20  \n","   2    |   240   |   1.067150   |     -      |     -     |   27.21  \n","   2    |   242   |   1.093936   |     -      |     -     |   1.87   \n","----------------------------------------------------------------------\n","   2    |    -    |   1.074214   |  1.078808  |   40.91   |  350.75  \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   3    |   20    |   1.050863   |     -      |     -     |   28.58  \n","   3    |   40    |   1.087352   |     -      |     -     |   27.18  \n","   3    |   60    |   1.070545   |     -      |     -     |   27.19  \n","   3    |   80    |   1.078168   |     -      |     -     |   27.19  \n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-3245b0ac98bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-32-4d87651a4f76>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, epochs, evaluation)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m# Perform a backward pass to calculate gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"XM6a35T-f6Qu"},"source":["import torch.nn.functional as F\n","\n","def bert_predict(model, test_dataloader):\n","    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n","    on the test set.\n","    \"\"\"\n","    # Put the model into the evaluation mode. The dropout layers are disabled during\n","    # the test time.\n","    model.eval()\n","\n","    all_logits = []\n","\n","    # For each batch in our test set...\n","    for batch in test_dataloader:\n","        # Load batch to GPU\n","        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n","\n","        # Compute logits\n","        with torch.no_grad():\n","            logits = model(b_input_ids, b_attn_mask)\n","        all_logits.append(logits)\n","    \n","    # Concatenate logits from each batch\n","    all_logits = torch.cat(all_logits, dim=0)\n","\n","    # Apply softmax to calculate probabilities\n","    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n","    \n","    return probs "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X4IeiktpgFNr"},"source":["probs = bert_predict(bert_classifier, val_dataloader) \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7KzJpCLsgx5E","executionInfo":{"status":"ok","timestamp":1602672598699,"user_tz":-420,"elapsed":906,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"6004da9f-12d0-4817-b7a6-6e6a7b5b31a9","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["probs_index = []\n","for i in probs:\n","  probs_index.append(np.argmax(i))\n","\n","probs_index = np.array(probs_index)\n","probs_index"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, ..., 1, 1, 1])"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"QQzepAo2pOBj"},"source":["y_val = np.array(y_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6gaJ7V4vhlRY","executionInfo":{"status":"ok","timestamp":1602672603876,"user_tz":-420,"elapsed":810,"user":{"displayName":"tân Phúc","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDKgBtrP3HG_eM7k1pazVmgUON4-FhFdANHuo1=s64","userId":"07473053315684123316"}},"outputId":"601d2f3c-aa80-458e-e3af-fb20233fef79","colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["print(sum(probs_index==0))\n","print(sum(probs_index==1))\n","print(sum(probs_index==2))\n","print(sum(y_val!=probs_index))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","2165\n","0\n","1409\n"],"name":"stdout"}]}]}